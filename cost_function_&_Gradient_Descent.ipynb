{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cost function & Gradient Descent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJwbm9nt_Coe"
      },
      "source": [
        "# Loss Fumction\r\n",
        "* An optimization problem need to minimize a loss function\r\n",
        "* Type of loss function\r\n",
        "    1. Qudratic Loss Function: least Square Method used in linear Regression\r\n",
        "    2. etc\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUynI5DRBmhA"
      },
      "source": [
        "# Gradient Descent\r\n",
        "*   optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost).\r\n",
        "*  best used when the parameters cannot be calculated analytically\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooeVjPjRCdS9"
      },
      "source": [
        "# Intuition for Gradient Descent\r\n",
        "*  Take a bowl of you would eat cereal \r\n",
        "*. bowl is a plot of the cost function (f).\r\n",
        "*  A random position on the surface of the bowl is the cost of the current values of the coefficients (cost).\r\n",
        "*  bottom of the bowl is the cost of the best set of coefficients, the minimum of the function\r\n",
        "*  goal is to continue to try different values for the coefficients, evaluate their cost and select new coefficients that have a slightly better (lower) cost.\r\n",
        "*  Repeat till you get the minimum value "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8vE-xz99a0z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}